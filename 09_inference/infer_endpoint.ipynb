{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Know features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_ORDER = [\n",
    "    \"store_id\",\n",
    "    \"is_weekend\",\n",
    "    \"is_holiday\",\n",
    "    \"max_temp_c\",\n",
    "    \"rainfall_mm\",\n",
    "    \"is_hot_day\",\n",
    "    \"is_rainy_day\",\n",
    "    \"base_price\",\n",
    "    \"discount_pct\",\n",
    "    \"is_promo\",\n",
    "    \"final_price\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"day_of_year\",\n",
    "    \"day_of_week_index\",\n",
    "    \"discount_amount\",\n",
    "    \"is_promo_or_holiday\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def df_to_csv_payload(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Reorder columns to FEATURE_ORDER and convert to headerless CSV string.\"\"\"\n",
    "    missing = [c for c in FEATURE_ORDER if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing features in input DataFrame: {missing}\")\n",
    "\n",
    "    X = df[FEATURE_ORDER].astype(np.float32).to_numpy()\n",
    "    lines = [\",\".join(map(str, row)) for row in X]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# Example: build a one-row DataFrame (fake data)\n",
    "df_request = pd.DataFrame([{\n",
    "    \"store_id\": 1,\n",
    "    \"is_weekend\": 0,\n",
    "    \"is_holiday\": 0,\n",
    "    \"max_temp_c\": 30.5,\n",
    "    \"rainfall_mm\": 2.0,\n",
    "    \"is_hot_day\": 1,\n",
    "    \"is_rainy_day\": 0,\n",
    "    \"base_price\": 12.5,\n",
    "    \"discount_pct\": 0.1,\n",
    "    \"is_promo\": 1,\n",
    "    \"final_price\": 11.25,\n",
    "    \"year\": 2024,\n",
    "    \"month\": 2,\n",
    "    \"day\": 15,\n",
    "    \"day_of_year\": 46,\n",
    "    \"day_of_week_index\": 3,\n",
    "    \"discount_amount\": 1.25,\n",
    "    \"is_promo_or_holiday\": 1,\n",
    "}])\n",
    "\n",
    "# payload = df_to_csv_payload(df_request)\n",
    "# print(\"Payload:\\n\", payload)\n",
    "\n",
    "# res = predictor.predict(payload)\n",
    "# print(\"Raw response:\", res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw body: 88.05634307861328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "region = \"us-east-1\"  # adjust if needed\n",
    "runtime_sm = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "# Build payload string using the same FEATURE_ORDER / df_to_csv_payload\n",
    "payload = df_to_csv_payload(df_request)\n",
    "\n",
    "response = runtime_sm.invoke_endpoint(\n",
    "    EndpointName=\"retail-demand-xgb-serverless-20251206-135312\",\n",
    "    ContentType=\"text/csv\",\n",
    "    Body=payload.encode(\"utf-8\"),\n",
    ")\n",
    "\n",
    "body = response[\"Body\"].read().decode(\"utf-8\")\n",
    "print(\"Raw body:\", body)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multishot Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_test_data_s3_uri: s3://sagemaker-us-east-1-423623839320/sagemaker-scikit-learn-2025-12-03-07-46-41-610/output/retail-test\n",
      "download: s3://sagemaker-us-east-1-423623839320/sagemaker-scikit-learn-2025-12-03-07-46-41-610/output/retail-test/test.csv to data_test/test.csv\n",
      "Raw body: 80.28925323486328\n",
      "92.33282470703125\n",
      "124.36448669433594\n",
      "83.60984802246094\n",
      "77.35962677001953\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "region = \"us-east-1\"  # adjust if needed\n",
    "runtime_sm = boto3.client(\"sagemaker-runtime\", region_name=region)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Reload test set (processed)\n",
    "%store -r processed_test_data_s3_uri\n",
    "print(\"processed_test_data_s3_uri:\", processed_test_data_s3_uri)\n",
    "\n",
    "test_csv_s3_path = processed_test_data_s3_uri.rstrip(\"/\") + \"/test.csv\"\n",
    "\n",
    "# Download test.csv locally\n",
    "!mkdir -p data_test\n",
    "!aws s3 cp $test_csv_s3_path data_test/test.csv\n",
    "\n",
    "df_test = pd.read_csv(\"data_test/test.csv\")\n",
    "df_sample = df_test.head(5)   # take first 5 rows\n",
    "\n",
    "\n",
    "payload = df_to_csv_payload(df_sample)\n",
    "\n",
    "# get a real-time SageMaker endpoint\n",
    "response = runtime_sm.invoke_endpoint(\n",
    "    EndpointName=\"retail-demand-xgb-serverless-20251206-135312\",\n",
    "    ContentType=\"text/csv\",\n",
    "    Body=payload.encode(\"utf-8\"),\n",
    ")\n",
    "\n",
    "body = response[\"Body\"].read().decode(\"utf-8\")\n",
    "print(\"Raw body:\", body)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science_on_aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
